{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Justin Hardy | JEH180008 | Dr. Mazidi | CS 4395.001**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this assignment is to (...)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas import DataFrame as DF\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# About the Data Set\n",
    "DESCRIPTION OF DATA SET GOES HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading in the Data Set\n",
    "We'll start by reading in both the train and test data from the files as data frames. We'll then combine the two data frames and cut down the amount of rows we'll use in the data by a substantial amount. Then do a 70/30 split (rather than the 90/10 split already done)."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before cut: (4000000, 3)\n",
      "Shape after cut: (400000, 3)\n",
      "   Type                                    Title  \\\n",
      "0     1                             Buyer beware   \n",
      "1     1                               The Worst!   \n",
      "2     1                                Oh please   \n",
      "3     1                     Awful beyond belief!   \n",
      "4     1  Don't try to fool us with fake reviews.   \n",
      "\n",
      "                                              Review  \n",
      "0  This is a self-published book, and if you want...  \n",
      "1  A complete waste of time. Typographical errors...  \n",
      "2  I guess you have to be a romance novel lover f...  \n",
      "3  I feel I have to write to keep others from was...  \n",
      "4  It's glaringly obvious that all of the glowing...  \n",
      "        Type                                           Title  \\\n",
      "399995     2                                       Amys Best   \n",
      "399996     2                                  Nice Anthology   \n",
      "399997     2  There are two Kent Harringtons -- buyer beware   \n",
      "399998     2                                 Awesome straps!   \n",
      "399999     2                               for my canoe rack   \n",
      "\n",
      "                                                   Review  \n",
      "399995  AMy Grants early work is some of her best if n...  \n",
      "399996  This is a nice anthology of some of Amy's work...  \n",
      "399997  Readers looking for more books by hardboiled a...  \n",
      "399998  I bought a second set of these straps (Had the...  \n",
      "399999  Just bought a pair, strapped my 17' canoe down...  \n"
     ]
    }
   ],
   "source": [
    "# Read train and test\n",
    "col_names = ['Type', 'Title', 'Review']\n",
    "df_partial_1 = pandas.read_csv('data/train.csv', names=col_names, header=None)\n",
    "df_partial_2 = pandas.read_csv('data/test.csv', names=col_names, header=None)\n",
    "\n",
    "# Combine the data frames\n",
    "df = pandas.concat([df_partial_1, df_partial_2], ignore_index=True)\n",
    "\n",
    "# Print Shape of Data Frame\n",
    "print(\"Shape before cut:\", df.shape)\n",
    "\n",
    "# Cut down Data Frame size\n",
    "df_type_1 = df.loc[df['Type'] == 1]\n",
    "df_type_2 = df.loc[df['Type'] == 2]\n",
    "df_type_1_cut = df_type_1\n",
    "df_type_2_cut = df_type_2\n",
    "\n",
    "# Take a tenth of the Data Frame's contents\n",
    "df_type_1 = df_type_1.iloc[:int(len(df_type_1)/10)]\n",
    "df_type_2 = df_type_2.iloc[:int(len(df_type_2)/10)]\n",
    "\n",
    "# Combine the two separate Data Frame back into the full Data Frame.\n",
    "df = pandas.concat([df_type_1, df_type_2], ignore_index=True)\n",
    "\n",
    "# Print Shape of Data Frame\n",
    "print(\"Shape after cut:\", df.shape)\n",
    "\n",
    "# Print Head/Tail of the Data Frame\n",
    "print(\"Final Data Frame (head and tail):\")\n",
    "print(df.head())\n",
    "print()\n",
    "print(df.tail())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text Preprocessing\n",
    "DESCRIPTION OF WHAT WE'LL DO IN THIS SECTION GOES HERE"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
